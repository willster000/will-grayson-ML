{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m test_files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(test_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Load and concatenate training and testing data\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_fraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use 10% of the data\u001b[39;00m\n\u001b[0;32m     25\u001b[0m test_df \u001b[38;5;241m=\u001b[39m load_and_concat(test_files, sample_fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m, in \u001b[0;36mload_and_concat\u001b[1;34m(files, sample_fraction)\u001b[0m\n\u001b[0;32m     15\u001b[0m         df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39msample_fraction, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)  \u001b[38;5;66;03m# Random sampling\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     df_list\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:380\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 380\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:443\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 443\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    446\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:505\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    502\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# Grayson's path\n",
    "#train_folder = \"C:\\\\Users\\\\grays\\\\Will-Grayson GitHub Repo\\\\will-grayson-ML\\\\six-class\\\\data\\\\train\\\\\"\n",
    "#test_folder = \"C:\\\\Users\\\\grays\\\\Will-Grayson GitHub Repo\\\\will-grayson-ML\\\\six-class\\\\data\\\\test\\\\\"\n",
    "\n",
    "# Will's path (comment out if not in use)\n",
    "train_folder = \"C:\\\\Users\\\\willg\\\\OneDrive\\\\CSCI\\\\summer-2024-work\\\\will-grayson-ML\\\\six-class\\\\data\\\\train\\\\\"\n",
    "test_folder = \"C:\\\\Users\\\\willg\\\\OneDrive\\\\CSCI\\\\summer-2024-work\\\\will-grayson-ML\\\\six-class\\\\data\\\\test\\\\\"\n",
    "\n",
    "# Function to load and concatenate CSV files from a list of file paths\n",
    "def load_and_concat(files, sample_fraction=None):\n",
    "    df_list = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        if sample_fraction:\n",
    "            df = df.sample(frac=sample_fraction, random_state=42)  # Random sampling\n",
    "        df_list.append(df)\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# List all CSV files in the train and test folders\n",
    "train_files = glob.glob(train_folder + \"*.csv\")\n",
    "test_files = glob.glob(test_folder + \"*.csv\")\n",
    "\n",
    "# Load and concatenate training and testing data\n",
    "train_df = load_and_concat(train_files, sample_fraction=0.1)  # Use 10% of the data\n",
    "test_df = load_and_concat(test_files, sample_fraction=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine target labels into a single column for multi-class classification\n",
    "# Assuming the labels are one-hot encoded\n",
    "target_columns = ['spoofing', 'benign', 'MQTT', 'recon', 'DDoS', 'DoS']\n",
    "train_df['target'] = train_df[target_columns].idxmax(axis=1)\n",
    "test_df['target'] = test_df[target_columns].idxmax(axis=1)\n",
    "\n",
    "# Specify feature columns (excluding the target columns)\n",
    "feature_columns = [col for col in train_df.columns if col not in target_columns + ['target']]\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = train_df[feature_columns]\n",
    "y_train = train_df['target']\n",
    "X_test = test_df[feature_columns]\n",
    "y_test = test_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target labels\n",
    "y_train_encoded = pd.get_dummies(y_train)\n",
    "y_test_encoded = pd.get_dummies(y_test)\n",
    "\n",
    "# Create a scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the training features and transform both training and testing features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grays\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build the DNN model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=len(feature_columns), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(len(target_columns), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9012 - loss: 0.2970 - val_accuracy: 4.6084e-04 - val_loss: 13.8254\n",
      "Epoch 2/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.1850 - val_accuracy: 5.9350e-04 - val_loss: 14.3702\n",
      "Epoch 3/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9279 - loss: 0.1822 - val_accuracy: 5.3066e-04 - val_loss: 15.7562\n",
      "Epoch 4/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9293 - loss: 0.1785 - val_accuracy: 5.7954e-04 - val_loss: 16.8306\n",
      "Epoch 5/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9284 - loss: 0.1796 - val_accuracy: 5.0273e-04 - val_loss: 18.0270\n",
      "Epoch 6/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9292 - loss: 0.1776 - val_accuracy: 5.1670e-04 - val_loss: 16.0760\n",
      "Epoch 7/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.1765 - val_accuracy: 5.8652e-04 - val_loss: 17.8875\n",
      "Epoch 8/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9296 - loss: 0.1762 - val_accuracy: 4.6084e-04 - val_loss: 17.5300\n",
      "Epoch 9/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9294 - loss: 0.1750 - val_accuracy: 6.4238e-04 - val_loss: 16.9810\n",
      "Epoch 10/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9290 - loss: 0.1758 - val_accuracy: 6.8428e-04 - val_loss: 18.1960\n",
      "Epoch 11/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9299 - loss: 0.1743 - val_accuracy: 5.4463e-04 - val_loss: 20.0246\n",
      "Epoch 12/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9296 - loss: 0.1742 - val_accuracy: 4.7480e-04 - val_loss: 17.9619\n",
      "Epoch 13/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9304 - loss: 0.1728 - val_accuracy: 2.5137e-04 - val_loss: 21.5722\n",
      "Epoch 14/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9291 - loss: 0.1753 - val_accuracy: 4.1894e-04 - val_loss: 20.6150\n",
      "Epoch 15/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9294 - loss: 0.1740 - val_accuracy: 7.1919e-04 - val_loss: 21.8722\n",
      "Epoch 16/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9300 - loss: 0.1729 - val_accuracy: 5.3066e-04 - val_loss: 22.7983\n",
      "Epoch 17/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9301 - loss: 0.1736 - val_accuracy: 5.1670e-04 - val_loss: 24.2813\n",
      "Epoch 18/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9291 - loss: 0.1743 - val_accuracy: 5.7954e-04 - val_loss: 25.9270\n",
      "Epoch 19/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.1732 - val_accuracy: 4.6782e-04 - val_loss: 26.3705\n",
      "Epoch 20/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9300 - loss: 0.1728 - val_accuracy: 0.0011 - val_loss: 26.4024\n",
      "Epoch 21/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.1728 - val_accuracy: 5.2368e-04 - val_loss: 23.3881\n",
      "Epoch 22/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9304 - loss: 0.1719 - val_accuracy: 4.1894e-04 - val_loss: 29.8543\n",
      "Epoch 23/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9293 - loss: 0.1733 - val_accuracy: 5.4463e-04 - val_loss: 26.7932\n",
      "Epoch 24/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9297 - loss: 0.1735 - val_accuracy: 4.4687e-04 - val_loss: 29.4320\n",
      "Epoch 25/25\n",
      "\u001b[1m4476/4476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9291 - loss: 0.1739 - val_accuracy: 4.5386e-04 - val_loss: 26.9504\n",
      "\u001b[1m5045/5045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 755us/step\n",
      "[[110955    753      0      0      3      0]\n",
      " [ 41670   1156      0      3      2      0]\n",
      " [     0      0     26    129     20      0]\n",
      " [     0      0      0   3552     71    138]\n",
      " [     2      0      1    181   2568     15]\n",
      " [     0      0      0     96      6     72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    spoofing       0.73      0.99      0.84    111711\n",
      "      benign       0.61      0.03      0.05     42831\n",
      "        MQTT       0.96      0.15      0.26       175\n",
      "       recon       0.90      0.94      0.92      3761\n",
      "        DDoS       0.96      0.93      0.94      2767\n",
      "         DoS       0.32      0.41      0.36       174\n",
      "\n",
      "    accuracy                           0.73    161419\n",
      "   macro avg       0.75      0.58      0.56    161419\n",
      "weighted avg       0.70      0.73      0.63    161419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train_encoded, epochs=25, batch_size=128, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_classes = y_pred.argmax(axis=1)\n",
    "y_test_classes = y_test_encoded.values.argmax(axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test_classes, y_pred_classes))\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=target_columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
