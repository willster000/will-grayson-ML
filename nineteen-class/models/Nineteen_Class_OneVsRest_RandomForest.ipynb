{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willg\\AppData\\Local\\Temp\\ipykernel_24264\\1012211632.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#import smote\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grayson's path\n",
    "#train_folder = \"C:\\\\Users\\\\grays\\\\Will-Grayson GitHub Repo\\\\will-grayson-ML\\\\nineteen-class\\\\data\\\\train\\\\\"\n",
    "#test_folder = \"C:\\\\Users\\\\grays\\\\Will-Grayson GitHub Repo\\\\will-grayson-ML\\\\nineteen-class\\\\data\\\\test\\\\\"\n",
    "\n",
    "# Will's path (comment out if not in use)\n",
    "train_folder = \"C:\\\\Users\\\\willg\\\\OneDrive\\\\CSCI\\\\summer-2024-work\\\\will-grayson-ML\\\\nineteen-class\\\\data\\\\train\\\\\"\n",
    "test_folder = \"C:\\\\Users\\\\willg\\\\OneDrive\\\\CSCI\\\\summer-2024-work\\\\will-grayson-ML\\\\nineteen-class\\\\data\\\\test\\\\\"\n",
    "\n",
    "# Function to load and concatenate CSV files from a list of file paths\n",
    "def load_and_concat(files, sample_fraction=None):\n",
    "    df_list = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        if sample_fraction:\n",
    "            df = df.sample(frac=sample_fraction, random_state=42)  # Random sampling\n",
    "        df_list.append(df)\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# List all CSV files in the train and test folders\n",
    "train_files = glob.glob(train_folder + \"*.csv\")\n",
    "test_files = glob.glob(test_folder + \"*.csv\")\n",
    "\n",
    "# Load and concatenate training and testing data\n",
    "train_df = load_and_concat(train_files, sample_fraction=0.1)  # Use 10% of the data\n",
    "test_df = load_and_concat(test_files, sample_fraction=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine target labels into a single column for multi-class classification\n",
    "# Assuming the labels are one-hot encoded\n",
    "target_columns = ['spoofing', 'benign', 'MQTT_DDoS_Connect_Flood', 'MQTT_DoS_Connect_Flood', \n",
    "    'MQTT_DDoS_Publish_Flood', 'MQTT_DoS_Publish_Flood', 'MQTT_Malformed_Data',\n",
    "    'Recon_OS_Scan', 'Recon_Ping_Sweep', 'Recon_Port_Scan', 'Recon_VulScan',\n",
    "    'DoS_ICMP', 'DoS_SYN', 'DoS_TCP', 'DoS_UDP',\n",
    "    'DDoS_ICMP', 'DDoS_SYN', 'DDoS_TCP', 'DDoS_UDP'\n",
    "]\n",
    "feature_columns = [col for col in train_df.columns if col not in target_columns]\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = train_df[feature_columns]\n",
    "y_train = train_df[target_columns]\n",
    "X_test = test_df[feature_columns]\n",
    "y_test = test_df[target_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_labels = label_encoder.fit_transform(y_train.idxmax(axis=1))\n",
    "y_test_labels = label_encoder.transform(y_test.idxmax(axis=1))\n",
    "\n",
    "# Create a scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the training features and transform both training and testing features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the sampling strategy\n",
    "#sampling_strategy = {0: 230339, 1: 80196, 2: 200000, 3: 200000, 4: 200666, 5: 1006603, 6: 150000, 7: 160000, 8: 363009, 9: 52881, 10: 214952, 11: 462480, 12: 514724, 13: 540498, 14: 704503, 15: 974359, 16: 987063, 17: 1887175, 18: 1998026}\n",
    "\n",
    "# Apply SMOTE to the scaled training data\n",
    "#smote = SMOTE(sampling_strategy=sampling_strategy, random_state=42)\n",
    "#X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest model and wrap it with OneVsRestClassifier\n",
    "model = OneVsRestClassifier(RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train_labels)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_labels = model.predict(X_test_scaled)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'actual': label_encoder.inverse_transform(y_test_labels),\n",
    "    'predicted': label_encoder.inverse_transform(y_pred_labels)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34959     0     0    11     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0 17221     1    15     1     2     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0     0 18256     3     0     0     1     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    7     0     5 36187     0     0     0     6     0     0     0     1\n",
      "      0     0     0     0     0     0     1]\n",
      " [    5     0     0     0  9834     0     0     4     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0     9     0     0     0  9851     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0     0     1     0     0     0  8209     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0     0     0     9     5     0     0 13741     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0  4192     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0   117     0   725\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     1     0   312     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0   850\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    137     0     0     0     0    33     5]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0   244     0   118     1    19     1]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0    11     0     0     2     6]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0    11     0  2228     2    12     9]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     6     0     4    24    69     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     1     0     5     0  3640   115]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     2    11    27   134]]\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "              DDoS_ICMP       1.00      1.00      1.00     34970\n",
      "               DDoS_SYN       1.00      1.00      1.00     17240\n",
      "               DDoS_TCP       1.00      1.00      1.00     18260\n",
      "               DDoS_UDP       1.00      1.00      1.00     36207\n",
      "               DoS_ICMP       1.00      1.00      1.00      9843\n",
      "                DoS_SYN       1.00      1.00      1.00      9860\n",
      "                DoS_TCP       1.00      1.00      1.00      8210\n",
      "                DoS_UDP       1.00      1.00      1.00     13755\n",
      "MQTT_DDoS_Connect_Flood       1.00      1.00      1.00      4192\n",
      "MQTT_DDoS_Publish_Flood       1.00      0.14      0.24       842\n",
      " MQTT_DoS_Connect_Flood       1.00      1.00      1.00       313\n",
      " MQTT_DoS_Publish_Flood       0.54      1.00      0.70       850\n",
      "    MQTT_Malformed_Data       1.00      0.78      0.88       175\n",
      "          Recon_OS_Scan       0.93      0.64      0.76       383\n",
      "       Recon_Ping_Sweep       1.00      0.58      0.73        19\n",
      "        Recon_Port_Scan       0.95      0.98      0.96      2262\n",
      "          Recon_VulScan       0.63      0.23      0.34       103\n",
      "                 benign       0.96      0.97      0.96      3761\n",
      "               spoofing       0.49      0.77      0.60       174\n",
      "\n",
      "               accuracy                           0.99    161419\n",
      "              macro avg       0.92      0.85      0.85    161419\n",
      "           weighted avg       0.99      0.99      0.99    161419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test_labels, y_pred_labels))\n",
    "print(classification_report(y_test_labels, y_pred_labels, target_names=label_encoder.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
