{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grayson's path\n",
    "train_folder = \"C:\\\\Users\\\\grays\\\\Will-Grayson GitHub Repo\\\\will-grayson-ML\\\\nineteen-class\\\\data\\\\train\\\\\"\n",
    "test_folder = \"C:\\\\Users\\\\grays\\\\Will-Grayson GitHub Repo\\\\will-grayson-ML\\\\nineteen-class\\\\data\\\\test\\\\\"\n",
    "\n",
    "# Will's path\n",
    "#train_folder = \"C:\\\\Users\\\\willg\\\\OneDrive\\\\CSCI\\\\summer-2024-work\\\\will-grayson-ML\\\\train\\\\\"\n",
    "#test_folder = \"C:\\\\Users\\\\willg\\\\OneDrive\\\\CSCI\\\\summer-2024-work\\\\will-grayson-ML\\\\test\\\\\"\n",
    "\n",
    "# List all CSV files in the train folder\n",
    "train_files = glob.glob(train_folder + \"*.csv\")\n",
    "test_files = glob.glob(test_folder + \"*.csv\")\n",
    "\n",
    "# Function to load and concatenate CSV files from a list of file paths\n",
    "def load_and_concat(files, sample_fraction=None):\n",
    "    df_list = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        if sample_fraction:\n",
    "            df = df.sample(frac=sample_fraction, random_state=42)  # Random sampling\n",
    "        df_list.append(df)\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Load and concatenate training and testing data\n",
    "train_files = glob.glob(train_folder + \"*.csv\")\n",
    "test_files = glob.glob(test_folder + \"*.csv\")\n",
    "train_df = load_and_concat(train_files, sample_fraction=0.1)  # Use 10% of the data\n",
    "test_df = load_and_concat(test_files, sample_fraction=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [col for col in train_df.columns if col not in [\n",
    "    'spoofing', 'benign', 'MQTT_DDoS_Connect_Flood', 'MQTT_DoS_Connect_Flood', \n",
    "    'MQTT_DDoS_Publish_Flood', 'MQTT_DoS_Publish_Flood', 'MQTT_Malformed_Data',\n",
    "    'Recon_OS_Scan', 'Recon_Ping_Sweep', 'Recon_Port_Scan', 'Recon_VulScan',\n",
    "    'DoS_ICMP', 'DoS_SYN', 'DoS_TCP', 'DoS_UDP',\n",
    "    'DDoS_ICMP', 'DDoS_SYN', 'DDoS_TCP', 'DDoS_UDP'\n",
    "]]\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = train_df[feature_columns]\n",
    "y_train = train_df[['spoofing', 'benign', 'MQTT_DDoS_Connect_Flood', 'MQTT_DoS_Connect_Flood', \n",
    "    'MQTT_DDoS_Publish_Flood', 'MQTT_DoS_Publish_Flood', 'MQTT_Malformed_Data',\n",
    "    'Recon_OS_Scan', 'Recon_Ping_Sweep', 'Recon_Port_Scan', 'Recon_VulScan',\n",
    "    'DoS_ICMP', 'DoS_SYN', 'DoS_TCP', 'DoS_UDP',\n",
    "    'DDoS_ICMP', 'DDoS_SYN', 'DDoS_TCP', 'DDoS_UDP']]\n",
    "\n",
    "X_test = test_df[feature_columns]\n",
    "y_test = test_df[['spoofing', 'benign', 'MQTT_DDoS_Connect_Flood', 'MQTT_DoS_Connect_Flood', \n",
    "    'MQTT_DDoS_Publish_Flood', 'MQTT_DoS_Publish_Flood', 'MQTT_Malformed_Data',\n",
    "    'Recon_OS_Scan', 'Recon_Ping_Sweep', 'Recon_Port_Scan', 'Recon_VulScan',\n",
    "    'DoS_ICMP', 'DoS_SYN', 'DoS_TCP', 'DoS_UDP',\n",
    "    'DDoS_ICMP', 'DDoS_SYN', 'DDoS_TCP', 'DDoS_UDP']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_labels = label_encoder.fit_transform(y_train.idxmax(axis=1))\n",
    "y_test_labels = label_encoder.transform(y_test.idxmax(axis=1))\n",
    "\n",
    "# Create a scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the training features and transform both training and testing features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert the scaled features to DataFrames\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=feature_columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    1    78     0     0     0     0     0     0     0     0     0     0\n",
      "      0    93     2     0     0     0     0]\n",
      " [   19  3422    26     0     0     3     0     0     0     0     0     0\n",
      "      2   282     7     0     0     0     0]\n",
      " [    0     0  4110     0     2     0     0     0     0     0     0     0\n",
      "     78     0     0     0     0     2     0]\n",
      " [    0     0   102     0     7     1     0     0     0     0     0     0\n",
      "    203     0     0     0     0     0     0]\n",
      " [   22     0     4     0    69     3     0     0     0     0     0     0\n",
      "      1   743     0     0     0     0     0]\n",
      " [    0     0     0     0     0   849     0     0     0     0     0     0\n",
      "      0     1     0     0     0     0     0]\n",
      " [    6    63    33     0     0     0     0     0     0     0     0     0\n",
      "      3    70     0     0     0     0     0]\n",
      " [    0    20    10     0     0     2     0     0     0    77     0     0\n",
      "     97   104     0     0    68     5     0]\n",
      " [    0    12     0     0     0     0     0     0     0     0     0     0\n",
      "      0     7     0     0     0     0     0]\n",
      " [    1    61     0     0     0     0     0     0     0   433     0     0\n",
      "    696   570     0     0   501     0     0]\n",
      " [    1    31    12     0     0     0     0     0     0     5     0     0\n",
      "     15    38     0     0     1     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0  9818\n",
      "      0    21     0     4     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "   9570   134     0     0     0   156     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0  8170     0     0     0    40     0]\n",
      " [    2     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     6 13553     0     0     0   194]\n",
      " [    0     0     1     0     0     1     0     0     0     0     0    44\n",
      "      0    14     0 34910     0     0     0]\n",
      " [    7     0     2     0     0     0     0     0     0     0     0     0\n",
      "     14   619     0     0 16597     1     0]\n",
      " [    2     0     0     0     0     1     0     0     0     0     0     0\n",
      "      0   138     0     0     0 18119     0]\n",
      " [    1     0     1     0     0     2     0     0     0     0     0     0\n",
      "      0    71 15443     0     0     0 20689]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.01      0.01       174\n",
      "           1       0.93      0.91      0.92      3761\n",
      "           2       0.96      0.98      0.97      4192\n",
      "           3       0.00      0.00      0.00       313\n",
      "           4       0.88      0.08      0.15       842\n",
      "           5       0.98      1.00      0.99       850\n",
      "           6       0.00      0.00      0.00       175\n",
      "           7       0.00      0.00      0.00       383\n",
      "           8       0.00      0.00      0.00        19\n",
      "           9       0.84      0.19      0.31      2262\n",
      "          10       0.00      0.00      0.00       103\n",
      "          11       1.00      1.00      1.00      9843\n",
      "          12       0.90      0.97      0.93      9860\n",
      "          13       0.74      1.00      0.85      8210\n",
      "          14       0.47      0.99      0.63     13755\n",
      "          15       1.00      1.00      1.00     34970\n",
      "          16       0.97      0.96      0.96     17240\n",
      "          17       0.99      0.99      0.99     18260\n",
      "          18       0.99      0.57      0.72     36207\n",
      "\n",
      "    accuracy                           0.87    161419\n",
      "   macro avg       0.61      0.56      0.55    161419\n",
      "weighted avg       0.91      0.87      0.87    161419\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grays\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\grays\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\grays\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initialize the AdaBoost model\n",
    "model = AdaBoostClassifier(n_estimators=100, algorithm='SAMME')\n",
    "\n",
    "# Convert one-hot encoded labels to integer labels for y_train\n",
    "y_train_labels = y_train.values.argmax(axis=1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train_labels)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_labels = model.predict(X_test_scaled)\n",
    "\n",
    "# Convert one-hot encoded labels to integer labels for y_test\n",
    "y_test_labels = y_test.values.argmax(axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test_labels, y_pred_labels))\n",
    "print(classification_report(y_test_labels, y_pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
