{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grayson's path\n",
    "train_folder = \"C:\\\\Users\\\\grays\\\\Will-Grayson GitHub Repo\\\\will-grayson-ML\\\\nineteen-class\\\\data\\\\train\\\\\"\n",
    "test_folder = \"C:\\\\Users\\\\grays\\\\Will-Grayson GitHub Repo\\\\will-grayson-ML\\\\nineteen-class\\\\data\\\\test\\\\\"\n",
    "\n",
    "# Will's path\n",
    "#train_folder = \"C:\\\\Users\\\\willg\\\\OneDrive\\\\CSCI\\\\summer-2024-work\\\\will-grayson-ML\\\\train\\\\\"\n",
    "#test_folder = \"C:\\\\Users\\\\willg\\\\OneDrive\\\\CSCI\\\\summer-2024-work\\\\will-grayson-ML\\\\test\\\\\"\n",
    "\n",
    "# List all CSV files in the train and test folders\n",
    "train_files = glob.glob(train_folder + \"*.csv\")\n",
    "test_files = glob.glob(test_folder + \"*.csv\")\n",
    "\n",
    "# Function to load and concatenate CSV files from a list of file paths\n",
    "def load_and_concat(files, sample_fraction=None):\n",
    "    df_list = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        if sample_fraction:\n",
    "            df = df.sample(frac=sample_fraction, random_state=42)  # Random sampling\n",
    "        df_list.append(df)\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Load and concatenate training and testing data\n",
    "train_files = glob.glob(train_folder + \"*.csv\")\n",
    "test_files = glob.glob(test_folder + \"*.csv\")\n",
    "train_df = load_and_concat(train_files, sample_fraction=0.1)  # Use 10% of the data\n",
    "test_df = load_and_concat(test_files, sample_fraction=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [col for col in train_df.columns if col not in [\n",
    "    'spoofing', 'benign', 'MQTT_DDoS_Connect_Flood', 'MQTT_DoS_Connect_Flood', \n",
    "    'MQTT_DDoS_Publish_Flood', 'MQTT_DoS_Publish_Flood', 'MQTT_Malformed_Data',\n",
    "    'Recon_OS_Scan', 'Recon_Ping_Sweep', 'Recon_Port_Scan', 'Recon_VulScan',\n",
    "    'DoS_ICMP', 'DoS_SYN', 'DoS_TCP', 'DoS_UDP',\n",
    "    'DDoS_ICMP', 'DDoS_SYN', 'DDoS_TCP', 'DDoS_UDP'\n",
    "]]\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = train_df[feature_columns]\n",
    "y_train = train_df[['spoofing', 'benign', 'MQTT_DDoS_Connect_Flood', 'MQTT_DoS_Connect_Flood', \n",
    "    'MQTT_DDoS_Publish_Flood', 'MQTT_DoS_Publish_Flood', 'MQTT_Malformed_Data',\n",
    "    'Recon_OS_Scan', 'Recon_Ping_Sweep', 'Recon_Port_Scan', 'Recon_VulScan',\n",
    "    'DoS_ICMP', 'DoS_SYN', 'DoS_TCP', 'DoS_UDP',\n",
    "    'DDoS_ICMP', 'DDoS_SYN', 'DDoS_TCP', 'DDoS_UDP']]\n",
    "\n",
    "X_test = test_df[feature_columns]\n",
    "y_test = test_df[['spoofing', 'benign', 'MQTT_DDoS_Connect_Flood', 'MQTT_DoS_Connect_Flood', \n",
    "    'MQTT_DDoS_Publish_Flood', 'MQTT_DoS_Publish_Flood', 'MQTT_Malformed_Data',\n",
    "    'Recon_OS_Scan', 'Recon_Ping_Sweep', 'Recon_Port_Scan', 'Recon_VulScan',\n",
    "    'DoS_ICMP', 'DoS_SYN', 'DoS_TCP', 'DoS_UDP',\n",
    "    'DDoS_ICMP', 'DDoS_SYN', 'DDoS_TCP', 'DDoS_UDP']]\n",
    "\n",
    "# Create a scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the training features and transform both training and testing features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   84    73     0     0     0     3     0     0     0     0     7     0\n",
      "      1     0     6     0     0     0     0]\n",
      " [  139  3362     1     0     1    38     3     0     1    20     0     0\n",
      "      1     0   195     0     0     0     0]\n",
      " [    0     0  4184     3     0     0     0     0     0     2     0     0\n",
      "      2     0     0     0     1     0     0]\n",
      " [    0     0    44   268     0     0     0     0     0     0     0     0\n",
      "      1     0     0     0     0     0     0]\n",
      " [    0    37     1     0   113   690     1     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0    19     0     0     0   831     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0    96    33     0     1     9    27     0     0     0     0     0\n",
      "      4     2     3     0     0     0     0]\n",
      " [    0    41     4     5     1     1     0    10     0   155     1     0\n",
      "      4     0     0     0   161     0     0]\n",
      " [    0    10     0     0     0     0     0     0     9     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [   33    66     0     0     0     2     0     1     0  1325    16     0\n",
      "     51     0     3     0   765     0     0]\n",
      " [    1    62     5     0     0     4     0     0     0     9     0     0\n",
      "     13     0     0     0     9     0     0]\n",
      " [    0    20     0     0     0     0     0     0     0     0     0    64\n",
      "      0     0     0  9759     0     0     0]\n",
      " [    0     0     3     0     1     0     0     1     0    47     0     0\n",
      "   5081     0     0     0  4727     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0    35     0     0     0  8175     0]\n",
      " [    0     6     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0    52     0     0     0 13697]\n",
      " [    0    14     0     0     0     0     0     0     0     0     0    41\n",
      "      0     0     0 34915     0     0     0]\n",
      " [    2    42     0     1     0     0     0     0     0    99     0     0\n",
      "    921     0     0     0 16175     0     0]\n",
      " [    0    11     0     0     0     0     0     0     0     0     0     0\n",
      "      0     8     0     0     0 18241     0]\n",
      " [    0    19     0     0     0     0     0     0     0     0     0     0\n",
      "      2     0   190     0     0     0 35996]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.48      0.39       174\n",
      "           1       0.87      0.89      0.88      3761\n",
      "           2       0.98      1.00      0.99      4192\n",
      "           3       0.97      0.86      0.91       313\n",
      "           4       0.97      0.13      0.24       842\n",
      "           5       0.53      0.98      0.68       850\n",
      "           6       0.87      0.15      0.26       175\n",
      "           7       0.83      0.03      0.05       383\n",
      "           8       0.90      0.47      0.62        19\n",
      "           9       0.80      0.59      0.68      2262\n",
      "          10       0.00      0.00      0.00       103\n",
      "          11       0.61      0.01      0.01      9843\n",
      "          12       0.84      0.52      0.64      9860\n",
      "          13       0.78      0.00      0.01      8210\n",
      "          14       0.12      0.00      0.01     13755\n",
      "          15       0.78      1.00      0.88     34970\n",
      "          16       0.74      0.94      0.83     17240\n",
      "          17       0.69      1.00      0.82     18260\n",
      "          18       0.72      0.99      0.84     36207\n",
      "\n",
      "    accuracy                           0.75    161419\n",
      "   macro avg       0.70      0.53      0.51    161419\n",
      "weighted avg       0.70      0.75      0.66    161419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Convert one-hot encoded labels to integer labels for y_train\n",
    "y_train_labels = y_train.values.argmax(axis=1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train_labels)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_labels = model.predict(X_test_scaled)\n",
    "\n",
    "# Convert one-hot encoded labels to integer labels for y_test\n",
    "y_test_labels = y_test.values.argmax(axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test_labels, y_pred_labels))\n",
    "print(classification_report(y_test_labels, y_pred_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
